{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import csv\n",
    "import torch\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始读入数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\Users\\10056\\Desktop\\科研\\data_set\\ml2022spring-hw1\\covid.test.csv', 'r') as f:\n",
    "    train_data = f.readlines()\n",
    " \n",
    "    train_data = [line.split('\\n') for line in train_data][1:]  #分行之后不要第一行\n",
    "    train_data = [each[0].split(',') for each in train_data]    #对于每一行 去掉后面的空格\n",
    "    print(len(train_data[0]))\n",
    "    train_data = np.array(train_data)         #转换成numpy的矩阵\n",
    " \n",
    "    train_x = train_data[:,1:-1]     # x是数据，y是标签 。第一个冒号表示所有行，第二个冒号表示\n",
    "    train_y = train_data[:,-1]      #列。所以x就是第2列到倒数第二列。y就是倒数第一列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', ..., '12.4525703', '9.4000244', '30.5508734'],\n",
       "       ['1', '0', '0', ..., '11.7475281', '7.4386058', '35.3648714'],\n",
       "       ['2', '0', '0', ..., '12.8980889', '10.2147107', '37.0287053'],\n",
       "       ...,\n",
       "       ['1075', '0', '0', ..., '13.6469982', '10.9437572', '32.5646431'],\n",
       "       ['1076', '0', '0', ..., '15.7997773', '11.4043682', '43.8621766'],\n",
       "       ['1077', '0', '0', ..., '14.1463771', '10.8294526', '33.4778761']],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', '0', '0', ..., '3.4721051', '12.4525703', '9.4000244'],\n",
       "       ['0', '0', '0', ..., '5.9923323', '11.7475281', '7.4386058'],\n",
       "       ['0', '0', '0', ..., '13.9516313', '12.8980889', '10.2147107'],\n",
       "       ...,\n",
       "       ['0', '0', '0', ..., '3.207936', '13.6469982', '10.9437572'],\n",
       "       ['0', '0', '0', ..., '2.9658171', '15.7997773', '11.4043682'],\n",
       "       ['0', '0', '0', ..., '2.6319415', '14.1463771', '10.8294526']],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30.5508734', '35.3648714', '37.0287053', ..., '32.5646431',\n",
       "       '43.8621766', '33.4778761'], dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def get_feature_importance(feature_data, label_data, k =4,column = None):\n",
    "    \"\"\"\n",
    "    此处省略 feature_data, label_data 的生成代码。\n",
    "    如果是 CSV 文件，可通过 read_csv() 函数获得特征和标签。\n",
    "    \"\"\"\n",
    "    model = SelectKBest(chi2, k=k)#选择k个最佳特征\n",
    "    X_new = model.fit_transform(feature_data, label_data)\n",
    "    #feature_data是特征数据，label_data是标签数据，该函数可以选择出k个特征\n",
    "    print('x_new', X_new)\n",
    "    scores = model.scores_\n",
    "    # 按重要性排序，选出最重要的 k 个\n",
    "    indices = np.argsort(scores)[::-1] #找到重要K个的下标\n",
    "    if column:\n",
    "        k_best_features = [column[i+1] for i in indices[0:k].tolist()]\n",
    "        print('k best features are: ',k_best_features)\n",
    "    return X_new, indices[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import csv\n",
    "import torch\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    " \n",
    "def get_feature_importance(feature_data, label_data, k =4,column = None):\n",
    "    \"\"\"\n",
    "    此处省略 feature_data, label_data 的生成代码。\n",
    "    如果是 CSV 文件，可通过 read_csv() 函数获得特征和标签。\n",
    "    \"\"\"\n",
    "    model = SelectKBest(chi2, k=k)#选择k个最佳特征\n",
    "    X_new = model.fit_transform(feature_data, label_data)\n",
    "    #feature_data是特征数据，label_data是标签数据，该函数可以选择出k个特征\n",
    "    print('x_new', X_new)\n",
    "    scores = model.scores_\n",
    "    # 按重要性排序，选出最重要的 k 个\n",
    "    indices = np.argsort(scores)[::-1] #找到重要K个的下标\n",
    "    if column:\n",
    "        k_best_features = [column[i+1] for i in indices[0:k].tolist()]\n",
    "        print('k best features are: ',k_best_features)\n",
    "    return X_new, indices[0:k]\n",
    " \n",
    " \n",
    "class covidDataset(Dataset):\n",
    "    def __init__(self, path, mode, feature_dim):\n",
    "        with open(path,'r') as f:\n",
    "            csv_data = list(csv.reader(f))\n",
    "            column = csv_data[0]\n",
    "            train_x = np.array(csv_data)[1:][:,1:-1]\n",
    "            train_y = np.array(csv_data)[1:][:,-1]\n",
    "            _,col_indices = get_feature_importance(train_x,train_y,feature_dim,column)\n",
    "            col_indices = col_indices.tolist()   #得到重要列的下标\n",
    "            csv_data = np.array(csv_data[1:])[:,1:].astype(float)\n",
    "            if mode == 'train':       #如果读的是训练数据 就逢5取4  indices是数据下标\n",
    "                indices = [i for i in range(len(csv_data)) if i % 5 != 0]\n",
    "                self.y = torch.LongTensor(csv_data[indices,-1])\n",
    "            elif mode == 'val':  #如果读的是验证数据 就逢5取1  indices是数据下标\n",
    "                indices = [i for i in range(len(csv_data)) if i % 5 == 0]\n",
    "                # data = torch.tensor(csv_data[indices,col_indices])\n",
    "                self.y = torch.LongTensor(csv_data[indices,-1])\n",
    "            else:      #如果读的是测试数据 就全取了\n",
    "                indices = [i for i in range(len(csv_data))]\n",
    "            data = torch.tensor(csv_data[indices,:]) #取行\n",
    "            self.data = data[:,col_indices]   #取列\n",
    "            self.mode = mode\n",
    "            self.data = (self.data - self.data.mean(dim=0,keepdim=True)) /self.data.std(dim=0,keepdim=True)     #这里将数据归一化。\n",
    "            assert feature_dim == self.data.shape[1]\n",
    " \n",
    " \n",
    "            print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
    "                  .format(mode, len(self.data), feature_dim))\n",
    " \n",
    "    def __getitem__(self, item):\n",
    "        if self.mode == 'test':\n",
    "            return self.data[item].float()\n",
    "        else :\n",
    "            return self.data[item].float(), self.y[item]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    " \n",
    "class myNet(nn.Module):\n",
    "    def __init__(self,inDim):\n",
    "        super(myNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(inDim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64,1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        if len(x.size()) > 1:\n",
    "            return x.squeeze(1)     #如果批量大小不为1 这里才需要展平。 \n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3d92321d22ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m      \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m      \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#开启训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m      \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "   for i in range(epoch):\n",
    "        start_time = time.time()\n",
    "        model.train()   #开启训练\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        for data in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            x , target = data[0].to(device), data[1].to(torch.float32).to(device)  \n",
    "            #从loader里取一批数据\n",
    "            pred = model(x)  #经过模型预测\n",
    "            bat_loss = loss(pred, target, model)  #计算loss\n",
    "            bat_loss.backward()     #梯度回传\n",
    "            optimizer.step()      #计算\n",
    "            train_loss += bat_loss.detach().cpu().item()    #记录loss值 注意要从gpu上取下来\n",
    "#再从张量里取出来\n",
    " \n",
    "        plt_train_loss . append(train_loss/trainset.__len__())  #记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
