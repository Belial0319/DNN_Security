# 13.Self-supervised learning(语音和影像上的应用)



## 13.1 Self-supervised learning for Speech

语音版的BERT和文字版的BERT在框架上并没有大的差别

在语音领域，Self-supervised Learning也用于各式各样的的任务上，并且效果很好

在没有大量标注的语音资料的时候，语音版的BERT可以给我们带来很大帮助：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720112323758.png" alt="image-20240720112323758" style="zoom:50%;" />

最开始输入还是语音讯号，和之前一样，做填空题，然后给出一些标注的资料（语音以及对应的文本）进行学习

文献表明，用Downstream Task的资料去Fine-tune语音版的BERT是没有必要的

## 13.2 Self-supervised Learning for Image

与在文字、语音上一样，Self-supervised Learning在影像上也是非常有潜力的

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/52db986f47f24280a7651dd3ad954fab.png" alt="img" style="zoom:50%;" />

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/b83c39af10f54f47b87fbf6d3efe8c0d.png" alt="img" style="zoom:50%;" />

## 13.3 在影像、语音上训练Self-supervised Learning的模型

下面介绍五大类方法

### 13.3.1 方法一：Generative Approaches

相当于填空题，给你一个声音或者图片片段，还原其内容

语音上和文字版BERT的做法一样，mask一些token，再去还原被盖起来的部分：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720113308691.png" alt="image-20240720113308691" style="zoom:50%;" />

相比文字版BERT，语音上也需要进行一些对应的改进：

由于语音上每个feature和他相邻的两个feature之间内容十分接近，一次只mask掉一个feature的话，**很容易根据相邻的两个feature猜出这个feature的内容**，这样model就学不到什么东西。**所以需要一次性mask掉一串feature**

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720113540748.png" alt="image-20240720113540748" style="zoom: 50%;" />

另外一个与文字不同的地方是，在语音上可以不在时间方向上做mask，可以mask一串向量的某几个dimension，这种mask的方法会让机器比较容易学到语者的资讯：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720113613530.png" alt="image-20240720113613530" style="zoom:50%;" />

GPT系列完全可以用在语音上。对于文字版的GPT，要做的任务是给一段文字，预测下一个token。但是对于语音版的GPT，由于每个feature和他相邻的feature十分接近，所以预测下一个token没什么挑战，**通常是预测往后数三个token之后的token：**

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720113758394.png" alt="image-20240720113758394" style="zoom:50%;" />

BERT、GPT的概念也完全可以用在影像上：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720113909886.png" alt="image-20240720113909886" style="zoom:50%;" />

把在文字上generative的方法应用在语音和影像上，相较于应用在文字上有一个较大的问题是，文字是用token表示的，而语音和影像包含了非常多的细节。

### 13.3.2 方法二：Predictive Approach

除了让machine去还原声音讯号、还原影像之外，可以设计一些简单的任务让机器去完成，希望机器通过学会这些简单的任务，能在复杂的任务上做的更好。例如下面的任务：

#### Image - predicting rotation

![image-20240720114119026](../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720114119026-1721446881060-7.png)

预测一下图片有没有被旋转，

#### Image - context prediction（判断两块image的相对位置）

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720114326707.png" alt="image-20240720114326707" style="zoom:50%;" />

例如给一个原始图片（猫）,判断猫耳朵和面部的相对位置

在语音、图像上，原来要生成的东西很复杂，因为语音、图像包含非常多的资讯。所以这里可以简化下要预测的东西：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720114506864.png" alt="image-20240720114506864" style="zoom:50%;" />

### 13.3.2 方法三：Contrastive Learning

#### Contrastive Learning for Image

语音和图像包含许多难以生成的细节。模型可以在不生成的情况下学习吗？

对比学习（ Contrastive Learning）的基本概念：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720120045400.png" alt="image-20240720120045400" style="zoom:50%;" />

同类型的图片是positive，不同类型的就是negative

判断标准就是生成的向量的距离远近



这里会有个问题，就是用于训练Self-supervised Learning model的data是没有标签的，如何判断两张图片之间是positive还是negative的关系？——SimCLR

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720120223811.png" alt="image-20240720120223811" style="zoom: 50%;" />



对图片进行data augmentation，同一张图片augmentation出来的图片之间是positive的关系，不同图片augmentation出来的图片之间是negative的关系。


#### Contrastive Learning for Speech

##### CPC / Wav2vec:

[wav2vec 2.0 详细介绍](https://zhuanlan.zhihu.com/p/390545403)

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720120654360.png" alt="image-20240720120654360" style="zoom:50%;" />

也就是把encoder的前面一部分输出当作输入，通过一个predicter得到一个vector，然后经过一个线性变换，使得他与同一个encoder下的其他输入距离越近越好，与其他句子的encoder后的输出越远越好。

##### VQ-wav2vec

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720121251555.png" alt="image-20240720121251555" style="zoom:50%;" />

这个时候encoder的输出变为一个token而不是vector。

##### VQ-wav2vec + BERT:

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720121410611.png" alt="image-20240720121410611" style="zoom:50%;" />

后面再利用BERT对于text进行计算。

##### VQ-wav2vec 2.0

<img src="https://img-blog.csdnimg.cn/3b73bfdae97647afb2674a4eda13628c.png" alt="img" style="zoom:67%;" />

Classification vs. Contrastive

<img src="https://img-blog.csdnimg.cn/ed712ac6d6974fcdbba4ea9c2ecf49c0.png" alt="img" style="zoom:50%;" />

Contrastive Learning的方法，存在一个很大的问题就是需要选择合适的negative examples

![img](../assets/13.Self-supervised learning(语音和影像上的应用)/4fc6b02cfa1b49f5ba4f5fe98adecc56.png)

既然选择negative example是一个比较困难的问题，下面方法四和方法五就避开选择negative example。

#### 方法四：Bootstrapping Approaches

如果只用positive example去训练模型，无论输入是什么，machine只需要输出相同的向量就行，就会出现collapse的现象：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720122736379.png" alt="image-20240720122736379" style="zoom:50%;" />

只用positive example的情况下，避免collapse发生：

关键技巧：左右两条路径的network架构不同、参数update的方式不同（左边不进行update，右边update后把Encoder的参数copy给左边的Encoder）

Bootstrapping也可以看做一种**Knowledge Distillation**（知识蒸馏）：

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/b8cdd4fe397f4565a400c371aaf94875.png" alt="img" style="zoom:50%;" />

下面是一些在图像和语音上使用Bootstrapping的model：

![image-20240720123207505](../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720123207505.png)

#### 方法五：Simply Extra Regularization

——positive example + regularization

方法五有两个代表作品：

​    ① Barlow Twins

​    ② Variance-Invariance-Covariance Regularization (VICReg)

下面介绍VICReg：只需要Invariance和Variance，就不会出现collapse的问题

<img src="../assets/13.Self-supervised learning(语音和影像上的应用)/image-20240720123623580.png" alt="image-20240720123623580" style="zoom:50%;" />