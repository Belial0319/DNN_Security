# 15 Auto-encoder自编码

## 基本认识

self-supervised learning：设计不需要标注数据的pre-train任务来训练模型，如填空题、预测下一个token。

**Auto-Encoder可以看作是 Self-Supervised Learning 的一种 Pre-Train 的方法。**

## 主要架构

![image-20240721151815877](../assets/15.Auto-encoder自编码/image-20240721151815877.png)

- Encoder 把一张图片读进来,它把这张图片**变成一个向量（Embedding，Representation，Code），**作为Decoder 的输入。架构可能类似于多层的network，CNN。
- Decoder 输入**向量**，产生一张图片。所以 Decoder 的 Network 的架构,可能会像是 GAN 裡面的 Generator

**训练的目标**是希望,**Encoder 的输入**跟 **Decoder 的输出,越接近越好**



**Reconstruction** ,重建：把图片看作是一个很长的向量的,希望这个向量跟 Decoder 的输出这个向量越接近越好

和我们之前学到的Cycle GAN相似，Cycle GAN：第一个 Generator,把 X Domain 的图片转到 Y Domain,另外一个 Generator,把 Y Domain 的图片转回来,希望最原先的图片,跟转完两次后的图片越接近越好。不过之前是无监督的，这里的vector也就是我们经常用的Embedding，

## 动机：“降维”（Dimension Reduction）

NN Encoder也就是把原始图片高纬度的图片，转化为低纬度的vector

**Dimension Reduction**降维

图片可以看作是一个很长的向量,但这个**向量太长了 不好处理。**

**⇒**丢到 **Encoder** 以后,输出另外一个向量,这个向量会**比较短。**

**⇒图片不再是一个很高维度的向量,它通过 Encoder 的压缩以后,变成了一个低维度的向量。**拿这个新的向量来做你接下来的任务。



> Bottleneck：输入是很宽的（维度很高）,输出也是很宽的，中间特别窄（维度低）





## 什么是Auto-encoder?

从图片上来看，就是把图片压缩再还原，high dim  --->  low dim  --->high dim



但是我们看到的图片它内在的橡塑不是毫无章法，而是可能有一定规律，临近像素可能会有一定相关性，举个例子：

<img src="../assets/15.Auto-encoder自编码/image-20240721152412075.png" alt="image-20240721152412075" style="zoom:33%;" />

一个较高维度的向量，由于他的“**变化有限**”，所以可能只需要很少的几维就能够表示各种变化情况。

如上图，$3\times3$的矩阵有$2^9$种变化情况，但是由于从训练中观测到，只有2种情况会出现，因此可以只用2维的向量进行表示。Encoder就能够实现这种转换，把复杂的信息用简单的方法表示。



## De-noising Auto-encoder

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc301305d-282d-45fe-b05c-b8435f6c3d9d%2FUntitled.png" alt="img" style="zoom:33%;" />

原来要输进去给 Encoder 的图片,加上一些Noies，要还原的是加入Noies之前的结果。Encoder 跟 Decoder,除了还原原来的图片这个任务以外,**还多了一个任务——自己学会把杂讯去掉**，**（应用技术：还原旧照）**

### BERT is a de-noising auto-encoder

同理BERT也就是**还原旧句**

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F6caadcba-37fb-41b6-9b48-626aa7009cda%2FUntitled.png" alt="img" style="zoom: 33%;" />

## Feature Disentanglement

提取Embedding不同维度的具体含义

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb74b5de4-5385-4ff1-bf11-17c8bb56b74b%2FUntitled.png" alt="img" style="zoom:50%;" />

因为Embedding向量能够还原回原来的数据，这说明Auto-encoder能够让Embedding中包含原数据中的所有信息。例如，把一段声音丢到 Encoder 裡面,变成向量，这个向量包含了,语音裡面所有重要的资讯,包括**这句话的内容是什么、还有这句话是谁说的**等等。

Feature Disentangle 想要做到的事情就是，希望在 Train 一个 Aauto-Encoder 的时候,同时有办法知道,这个 Representation/Embedding/Code**哪些维度代表了哪些信息**

### Application：Voice Conversion（变声器）



我们来看一下最开始的方法

![image-20240721154430486](../assets/15.Auto-encoder自编码/image-20240721154430486.png)

让A和B念一样的词，利用supervised的方法实现变声转换。

但是这有很多问题，比如转化人不是用的同一种语言等

现在的方法是各说各的就可以提取对方声音信息。

![image-20240721154624534](../assets/15.Auto-encoder自编码/image-20240721154624534.png)

给任意的语音信息就可以



<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd70713d4-a118-49dd-b665-6a0cef79de7c%2FUntitled.png" alt="img" style="zoom:50%;" />

由于我们**预先知道向量中哪些维度代表语音的内容、哪些维度代表语音的“声音”**，只要把其中一人说话的内容的部分取出来,把另一人说话的声音特征的部分取出来,把它拼起来,丢到 Decoder 里面,就可以实现变声。

也就是**A说话内容的维度**+**B说话的音色的维度**加起来输出

## Discrete Latent Representation——控制Embedding的形式，便于充分利用

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fab974760-336e-472a-9743-c8cffa9b692f%2FUntitled.png" alt="img" style="zoom:33%;" />

- 一般地，Embedding的各位都是实数数字
- **Binary**，每一个维度,它就代表了**某种特征的有或者是没有**，更易解释输出的含义

> 比如，输入的这张图片,如果是女生,可能第一维就是 1,男生第一维就是 0 如果有戴眼镜,就是第三维 1,没有戴眼镜 就是第三维是 0,

- **One-Hot**，也许就可以做到完全在没有,完全没有Llabel Data 的情况下,让**机器自动学会分类**

> 手写数字辨识,你有 0 到 9 的图片Train 一个这样子的 Aauto-Encoder,然后强迫中间的 Latent Representation,强迫中间的这个 Code 是 One-Hot Vector， 正好设个 10 维，就有 10 种可能的 One-Hot 的 Code,也许每一种 One-Hot 的 Code,正好就对应到一个数字

这里也就是我们可以指定Embedding的形式，将输出作为我们熟悉的内容

### VQVAE,Vector Quantized Variational Aauto-Encoder

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F88187759-3f86-44a9-91f8-d2f501abd9ae%2FUntitled.png" alt="img" style="zoom: 33%;" />

1. 输入一张图片,Encoder输出一个向量,这个向量它是一般的向量,是 Continuous 的
2. 接下来有一个 Codebook,有一排向量,这排向量也是 Learn 出来的。把 Encoder 的输出,去跟这排向量都去算个**相似度（跟 Self-attention 有点像）**,把相似度最大的那个 Vector 拿出来。

**好处：Discrete Latent Representation**

假设你 Codebook 裡面有 32 个向量,那你 Decoder 的输入就只有 32 种可能,等于就是让你的这个 Embedding,是离散的,它没有无穷无尽的可能。

> 用在语音上,你就是一段声音讯号输进来,通过 Encoder 以后产生一个向量。接下来计算相似度,把最像的那个向量拿出来丢给 Decoder,再输出一样的声音讯号,这个时候你会发现说你的 Codebook 可能可以学到最基本的发音部位Phonetic。

这对于有固定输入的事务比较实用，比如说我的中文发音只有元音辅音以及声调组合，我们在得到一段声音序号的时候，可以通过Encoder得到与当前片段最接近的发音，从而把整个发音输给Decoder

## Text as Representation

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F8cf86ed3-9c37-4aeb-8d82-25c4e28e9695%2FUntitled.png" alt="img" style="zoom: 33%;" />

Representation 能不能是一段文字?

这里的Auto-Encoder,是一个 seq2seq2seq 的 Auto-Encoder,它把长的 Sequence 转成短的 Sequence,再把短的 Sequence 还原回长的 Sequence。这个短的sequence，实际上代表了文章的“摘要”，是文章中最精华的内容，可以通过 Decoder 还原回原来的文章。

但是训练时发现，短的sequence不可读，他是两个模型之间的“暗号”。

改进：再用 GAN 的概念,加上一个 Discriminator⇒CycleGAN

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F564e0c55-0ba1-400d-8389-1e895840ee0c%2FUntitled.png" alt="img" style="zoom:33%;" />

Discriminator 看过人写的句子,所以它知道人写的句子长什么样子。Encoder 要想办法产生一段句子,这段句子不只可以透过 Decoder还原回原来的文章,还要是 Discriminator 觉得像是人写的句子。期待通过这个方法,就可以强迫 Encoder,不只产生一段密码可以给 Decoder 去破解,而是产生一段人看得懂的摘要。

训练时，用 RL 硬做。

### Tree as Embedding

例如：

<img src="../assets/15.Auto-encoder自编码/image-20240721155948288.png" alt="image-20240721155948288" style="zoom:50%;" />

但是也会出现问题：

<img src="../assets/15.Auto-encoder自编码/image-20240721160011275.png" alt="image-20240721160011275" style="zoom: 50%;" />



#### More Applications

##### Generator

<img src="../assets/15.Auto-encoder自编码/image-20240721160056683.png" alt="image-20240721160056683" style="zoom:50%;" />

Decoder 正好是吃一个向量,产生一张图片，可以把它当做一个 Generator 来使用。

##### Compression

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff29322de-86b9-4308-9a91-9f0d8f2fd0d7%2FUntitled.png" alt="img" style="zoom: 33%;" />

可以把 Encoder 的输出,当做是一个压缩的结果。Encoder 做的事情,就是压缩, Decoder 做的事情,就是解压缩。

这个压缩,它是那种 lossy 的压缩,**会失真。没有办法 Train 到说输入的图片跟输出的图片100% 完全一模一样,**

## Anomaly Detection（异常检测）

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc79fb1d5-3fba-4fd0-a3d9-7451da1ed69e%2FUntitled.png" alt="img" style="zoom:33%;" />

**来了一笔新的资料,它到底跟我们之前在训练资料裡面看过的资料相不相似。**

- 给它一笔新的资料,如果这笔新的资料,看起来像是训练资料裡面的 Data,就说它是正常的
- 如果看起来不像是训练资料裡面的 Data,就说它是异常的

![image-20240721160354683](../assets/15.Auto-encoder自编码/image-20240721160354683.png)

一笔资料**是正常或异常,取决于你的训练资料长什么样子**

### 应用

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd3550e44-09fa-46fd-8079-d85136641833%2FUntitled.png" alt="img" style="zoom: 33%;" />

- **诈欺侦测。**假设你的训练资料裡面,有一大堆信用卡的交易纪录，训练一个异常检测的模型。有一笔新的交易纪录进来,可以让机器帮你判断,这笔纪录算是正常的 还是异常的。
- **网路侵入侦测。**你收集到一大堆正常的连线的纪录,训练出一个异常检测的模型，看看新的连线,它是正常的连线 还是异常的连线
- **癌细胞检测。**收集到一大堆正常细胞的资料,拿来训练一个异常检测的模型,看到一个新的细胞,它可以知道这个细胞有没有突变,是不是一个癌细胞

### 难点：收集资料——One Class

我们往往假设,我们有一大堆正常的资料,但我们几乎没有异常的资料,所以它不是一个一般的分类的问题。这种分类的问题又叫做 One Class 的分类问题。

对于Auto-Encoder，**根据是否能够被还原，判断是否为“异常”**

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F30a7a4d9-2ae8-4dae-a75c-94f40382f685%2FUntitled.png" alt="img" style="zoom: 50%;" />

<img src="../assets/15.Auto-encoder自编码/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F96b025ed-dcb5-4cff-bdff-8187edbc8b3a%2FUntitled.png" alt="img" style="zoom:33%;" />

计算一张照片通过 Encoder,再通过 Decoder 以后,它的变化有多大,就可以去**计算这个输入的照片,跟这个输出的照片,它们的差异有多大。**

- 如果差异很小,你的 Decoder 可以顺利地还原原来的照片,代表这样类型的照片,是在训练的时候有看过的。
- 反过来说,假设有一张照片是训练的时候没有看过的，就很难把它还原回来,如果你计算输入跟输出的差异,发现差异非常地大。

根据reconstruction的好坏来判断训练时是否有看过同类型照片。

 