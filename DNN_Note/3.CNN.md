# 3. CNN

Image Classification

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619153157312.png" alt="image-20240619153157312" style="zoom:33%;" />

全连接网络：

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619153304047.png" alt="image-20240619153304047" style="zoom:33%;" />

缺点：参数太多了。

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619153508056.png" alt="image-20240619153508056" style="zoom:33%;" />

## 3.1 卷积（Convolution）

**观测1**

此时对于图片的输入，不需要很多参数，可以把每一个神经元看一个特征捕捉器，比如说看一只鸟，要看嘴巴、眼睛、爪子，通过这些特征集合，可以判定这是一只鸟。所以一个特征捕捉器其实不需要捕捉整个图片的参数，只用看特定片区即可。

**简化1-1：感受野（Receptive field）**

对于每一个神经元可以只接受一个特定区域的数据，称之为**感受野（Receptive field）**，

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619153955258.png" alt="image-20240619153955258" style="zoom:33%;" />

此时会有问题
**Q1：**不同neurons能不能覆盖到同一区域？

**A1**：**神经元可以重叠**，多个神经元可以重叠到一个像素区域。

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619155219799.png" alt="image-20240619155219799" style="zoom:33%;" />



**Q2：**能不能一个neuron只包含一个channel？

**A2：**可以的



**Q3: **Receptive field能不能是其他形状，不是正方形

**A3：**都是可以自己设计的



**简化1-2：常规设置（Typical Setting）**

**One neurons**：

**All channels + Kernel size**(e.g. 3*3)* **+ Stride**(移动步数. often set 1 or 2) **+Padding**(补齐)

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619160336329.png" alt="image-20240619160336329" style="zoom: 50%;" />

**观测2**

上面说了，一个神经元相当于侦察一个特征，而每一个神经元都会有固定的侦察区域，若此时特征出现的位置不一样，会不会引起识别缺陷？例如，现在一个检查嘴巴的神经元位于图片左上方，现在来了一个在图片中间的鸟，它的嘴巴也在图片中央，这样会不会引起识别问题？

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619160842145.png" alt="image-20240619160842145" style="zoom: 50%;" />

就好比现在，有一个大学有很多学院，有点学院人数多，有的人数少，现在每个院都要开设机器学习课程，是每个院安排一个老师讲课好，还是教务处统一弄一个大班教学好？

**简化2**

这里引入共享参数：（相当于各个学院要学机器学习课程的人可以共享一个老师去上课）

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619161403501.png" alt="image-20240619161403501" style="zoom:33%;" />

此时权重是相同的，但是输入的区域数据不同。



这里注意：每一个接收域有一组神经元，例如一个receptive field有64 neurons，

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619161754823.png" alt="image-20240619161754823" style="zoom:50%;" />

 **同组神经元负责观测同一接受域可能出现的不同特征，且不同组的相对应的神经元可以共享参数**

**总结：**

CNN 有大的model bias，model的bias就是模型的局限性，比如CNN就不能像fully connected network可以表示那么多的函数，比较容易过拟合

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619162611224.png" alt="image-20240619162611224" style="zoom: 50%;" />

**另外一种解释CNN**

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619162813152.png" alt="image-20240619162813152" style="zoom:33%;" />

把一个filter看作一3*3的tensor,其参数可以通过梯度下降算出来，相当于就是卷积核

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619163014775.png" alt="image-20240619163014775" style="zoom:33%;" />

此时判断特征就通过像素值经过卷积核后的值，例如，现在要判定像素矩阵为单位阵，并作为一个特征。现在的filter1的正对角线为全1，其他都为-1，若得到的卷积结果为3，就说明目标像素块的对角线全为1，其它元素全为0。这就得到了特征。

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619163447378.png" alt="image-20240619163447378" style="zoom:50%;" />

经过所有的filter后可以得到一个**Feature Map**

对Feature Map可以继续进行卷积运算

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619163816445.png" alt="image-20240619163816445" style="zoom:33%;" />

原本是$6*6*1$，一层卷积后（64个filter，其中filter的参数为$3*3*1$）得到$4*4*64$，再1通过下一层卷积。下一层filter的参数必须为：$3*3*64$，

此时filer的参数必须为$(receptive filed.legth * receptive field.width * inputs.channels$)

这里有一个疑问，下一层的filter设为3*3，是否太小了，其实不然：



<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619164701684.png" alt="image-20240619164701684" style="zoom: 50%;" />

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619164708477.png" alt="image-20240619164708477" style="zoom:50%;" />

此时可以看到下一层最右下角$3*3$的-2,其实是由第一层$5*5$处的区域得到的

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619165037406.png" alt="image-20240619165037406" style="zoom:50%;" />

第一个版本里面的神经元就是第二版里面的filter

## 3.2 池化（Pooling）

Max Pooling

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619171308657.png" alt="image-20240619171308657" style="zoom:33%;" />

除了Max Pooling外也有mean min pooling

主要是对特征提取后的图片进行压缩，并尽大可能地保存特征。

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619171415477.png" alt="image-20240619171415477" style="zoom:33%;" />

<img src="https://pic2.zhimg.com/80/v2-e9a5eb5674823648ebf4c58dcca8d0ad_720w.webp" alt="img" style="zoom:50%;" />

一般都是一段卷积后加一段池化，但是有时候如果需要提取精细的特征，也会采用full conv来进行神经网络的构建

## 3.3 CNN一般步骤

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619171640579.png" alt="image-20240619171640579" style="zoom: 50%;" />

## 3.4 学习推荐

[【数之道 08】走进"卷积神经网络"，了解图像识别背后的原理_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1R5411w715/?spm_id_from=333.337.search-card.all.click&vd_source=4ac244f0055c8de1d0f010d963ffd132)

例如现在需要识别一个数字：

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619172330475.png" alt="image-20240619172330475" style="zoom:33%;" />

它现在由$6*6$​​的像素点组成，只有0和1

### Step1 卷积

#### ①设计卷积核（此处人工设计）

卷积核采用

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619172426414.png" alt="image-20240619172426414" style="zoom: 50%;" />

分别来提取垂直特征和水平特征

#### ②卷积计算

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619172544151.png" alt="image-20240619172544151" style="zoom: 50%;" />

可以看到垂直的特征被很好的提取出来，但是水平特征没有很好表出。分析原因可能是因为原图片水平特征位于边缘位置，此时进行卷积过程未能被提取到，对于边缘特征提取，需要采用Padding

#### ③Zero Padding

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619172751478.png" alt="image-20240619172751478" style="zoom:50%;" />

此时可以看到明显的水平和垂直特征



### Step 2 池化

​                                  <img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619173113731.png" alt="image-20240619173113731" style="zoom:50%;" />       -------------------Max pooling------------→           ![image-20240619173124609](C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619173124609.png)                

### Step 3 扁平化

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619173523915.png" alt="image-20240619173523915" style="zoom:67%;" />

#### Step 4 全连接隐藏层

![image-20240619173633157](C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619173633157.png)

### 完整流程



<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619173557137.png" alt="image-20240619173557137" style="zoom:67%;" />

CNN直观动画网站：https:/poloclub.github.io/cnn-explainer/



![image-20240619173838196](C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619173838196.png)

 

## 3.5 CNN缺陷

CNN对于图片的尺寸放缩和旋转，无法实现既定的效果，最后flatten会出现错误。对于图片放大后，其所设定的neuron会失去效果，如何解决？



**CNN并不存在几个特性：**

1.Scaling的特性，filter size尺寸固定的情况下，大只狗与小只狗的形状并没有办法自动缩放辨识。
2.Rotation的特性，『3』转过来看起来对机器而言就是『m』。
3.也许仅有些许的Translation，但移动过多情况下对CNN来说也是不一样的。





<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619182028339.png" alt="image-20240619182028339" style="zoom:50%;" />

## 3.6 **Spatial Transformer Layer**



[Spatial Transformer Networks_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1ct411M7s6/?spm_id_from=333.337.search-card.all.click&vd_source=4ac244f0055c8de1d0f010d963ffd132)

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619182112369.png" alt="image-20240619182112369" style="zoom: 50%;" />

上图范例，也许照片上有着缩小的『5』、『6』，但对机器而言两个数字应该就是很大，即使是单纯的缩放，对CNN而言也是不一样的东西。
因此Spatial [Transformer](https://so.csdn.net/so/search?q=Transformer&spm=1001.2101.3001.7020) Layer想做的事就是将图片做旋转缩放，让特征可以符合机器识别。
Spatial Transformer [Layer](https://so.csdn.net/so/search?q=Layer&spm=1001.2101.3001.7020)本身也是一个NN layer，可以跟CNN并在一起直接训练，不仅可以Transform输入，所有的feature map都可以。

### 3.6.1 核心理论

![image-20240619185148409](C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619185148409.png)

也就是如何对图像进行变换，通常就是对像素点进行变换，上图左是transform之前的照片Layer I-1，上图右是transform之后的照片Layer I-2，明显的发现到这个transform是将照片做了平移。

一般fully connect layer来说可以将Output视为Input与Weight的计算加总而得，它也可以做的到Transformation，只要对Weight做一些适当的调整。

例如下图：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191229145007228.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU4NTcxMg==,size_16,color_FFFFFF,t_70)

现在有原始图片数据，以及目标图片数据，可以通过神经网络NN进行学习，得到$w_{nm,ij}^l$。并可以得到想要的效果

### 3.6.2 Image Transformation

同样可以对图片进行坐标变换，实现图片的放大、缩小、旋转

![img](https://img-blog.csdnimg.cn/20191229145044926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU4NTcxMg==,size_16,color_FFFFFF,t_70)

这边说明照片缩放与平移的作法，原值乘上参数加上平移值。

右上图范例为放大两倍，因此乘上参数2，不做平移，因此最后加0。

右下图范例为缩小两倍并且移至右上，因此乘上参数0.5最后加上平移值0.5。

<img src="https://img-blog.csdnimg.cn/20191229145405877.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU4NTcxMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

同理可以通过旋转矩阵进行图片旋转

$\begin{bmatrix}x'\\y'\end{bmatrix}=\begin{bmatrix}cos\theta&-sin\theta\\sin\theta&cos\theta\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}+\begin{bmatrix}b_1\\b_2\end{bmatrix}$



### 3.6.3 ST层(Spatial Transformer Layer)

<img src="C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619190104294.png" alt="image-20240619190104294" style="zoom:33%;" />

即对输入输出的数据进行坐标变换，此时只有6个参数,可以通过NN学习得到。

<img src="https://img-blog.csdnimg.cn/20191229145202362.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU4NTcxMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

(x,y),(x′,y′)是图像的索引，当(x′,y′)=(2,3),带入上面公式，可(x,y)=(1,2),其他的变换类似，结果如上图的箭头。

#### ①非整数问题

如果现在不是整数，

<img src="https://img-blog.csdnimg.cn/20191229145214680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU4NTcxMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 50%;" />

此时输出为[1.6 2.4]，最后应该要落到[2 2]处，现在我们一般是采取四舍五入，但是这怎么计算？

若进行四舍五入，此时的NN参数无法使用梯度，因为当你的参数稍微改变一点，其输出参数也不会右变化，四舍五入以后都是一样的，因此输出没有任何变化，此时微分为0.

#### ②双插值方法

<img src="https://img-blog.csdnimg.cn/2019122914523525.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU4NTcxMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

要处理小数点问题，就需要利用Interpolation，求出来的数值是有小数的，而这个小数索引实际上是在四个点$\mathrm{a_{(12)}^{l-1},a_{(13)}^{l-1},a_{(22)}^{l-1},a_{(23)}^{l-1}}$的区间内，我们不单纯的参考它跟距离最近的那个点$\mathbf{a}_{(22)}^{1-1}$，而是四个点的数值都参考。

这种情况下NN参数有些微的变化的时候Output也会有些微的变化，就可以利用梯度下降来优化求解了。

### 3.6.3 完整STN网络结构

<img src="https://img-blog.csdnimg.cn/2019122914530833.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU4NTcxMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

这个网络可以加入到CNN的任意位置，而且相应的计算量也很少。
将 spatial transformers 模块集成到 cnn 网络中，允许网络自动地学习如何进行 featuremap 的转变，从而有助于降低网络训练中整体的代价。定位网络中输出的值，指明了如何对每个训练数据进行转化。

![image-20240619191148479](C:\Users\10056\Desktop\科研\学习笔记\assets\image-20240619191148479.png)

注意 ST层的参数是整个网络一起运算得到的。相当于自动找到最适合CNN的识别区域。

### 3.6.4 应用场景

1.翻译杂乱的MNIST： 应用于MINIS上，不论数值如何的平移、旋转，对Output都没有影响。
2.街景门牌号
3.鸟类的辨识案例
