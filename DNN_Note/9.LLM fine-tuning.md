# 9 Finetuning

有什么用？

类似与迁移学习

## 9.1 微调1-图像识别

![image-20240705151432486](../assets/9.LLM fine-tuning/image-20240705151432486.png)

上图是传统的网络结构，对于图像识别领域，我们要对图像数据集进行识别，在Pre-training中需要原始数据集数据集，

### 9.1.1 概述

![image-20240705151549958](../assets/9.LLM fine-tuning/image-20240705151549958.png)

但现在我们想自己弄一个数据集进行我自己的模型训练，由于数据集标注很贵，那么我应该如何在训练自己的模型过程中同时保证自己数据集的隐私性？

<img src="../assets/9.LLM fine-tuning/image-20240705151729385.png" alt="image-20240705151729385" style="zoom:50%;" />

也就是可以把中间的特征提取过程拿过来使用。

![image-20240705151755388](../assets/9.LLM fine-tuning/image-20240705151755388.png)

我们保存中间特征提取层的特征信息参数，然后调整最终的输出层即可。比如说现在我们都是使用resnet18,这样可以借用别人的参数。

但是注意，对于迁移过来的参数并不是一成不变的，也是可以人为地改变，可以同时一起变，也可以固定一部分参数不变，改变一下其他参数

### 9.1.2 训练

![image-20240705152106850](../assets/9.LLM fine-tuning/image-20240705152106850-1720164069175-1.png)



#### 重用分类器权重

对于重复的参数分类也可以直接使用

![image-20240705152124996](../assets/9.LLM fine-tuning/image-20240705152124996.png)

此外可以固定一些层进行学习。

#### 固定底层学习参数

![image-20240705152214648](../assets/9.LLM fine-tuning/image-20240705152214648.png)

越低层的东西都是一些基础的东西，而层数越高，对于目标的相关性越大，因此可以选择固定底层学习参数





## 9.2 微调2-大预言模型

<img src="../assets/9.LLM fine-tuning/image-20240705152414951.png" alt="image-20240705152414951" style="zoom:50%;" />

相当于一个定制化的过程，可以对于特定的输入进行额外数据引入实现微调，实现更加细致的输出效果。chatgpt也是经过微调后的产品。

<img src="../assets/9.LLM fine-tuning/image-20240705152505311.png" alt="image-20240705152505311" style="zoom:50%;" />

### 9.2.1 Finetuning概述

#### 微调优势

<img src="../assets/9.LLM fine-tuning/image-20240705152628119.png" alt="image-20240705152628119" style="zoom:33%;" />

也就是可以有更好的输出表现，以及可以保护本地数据的隐私、GPU消费、以及可靠性

#### 示例

![image-20240705152804504](../assets/9.LLM fine-tuning/image-20240705152804504.png)

上图是**不使用微调**后，根据本地语料库输出的结果，可以看到结果很糟糕。

![image-20240705152905452](../assets/9.LLM fine-tuning/image-20240705152905452.png)

上图是**使用微调**后，根据本地语料库输出的结果，可以看到结果比较符合实际人的思维语言

### 9.2.2 微调应用场景

#### Pre-training

首先就是预训练，从开始的未知随机参数，到后面模型进行参数学习后得到一个成熟模型。其中的语料数据来源于互联网

<img src="../assets/9.LLM fine-tuning/image-20240705153439903.png" alt="image-20240705153439903" style="zoom:50%;" />

比如是现在有一个Once upon…………LLM模型就是通过预测下一个token的概率，使得下一个token的数据是upon

对于预训练模型也有一些弊端，比如说网络中有很多问题

<img src="../assets/9.LLM fine-tuning/image-20240705154201940.png" alt="image-20240705154201940" style="zoom:50%;" />

如果他们属于同一个数据集，那么在训练的过程中，LLM模型会导致一定问题，比如：

<img src="../assets/9.LLM fine-tuning/image-20240705154244712.png" alt="image-20240705154244712" style="zoom:50%;" />

输入一个问题，它会联想到另外一个问题。

#### Finetuning after pretraining

<img src="../assets/9.LLM fine-tuning/image-20240705170128265.png" alt="image-20240705170128265" style="zoom:33%;" />

#### 微调作用

![image-20240705170244402](../assets/9.LLM fine-tuning/image-20240705170244402.png)

一个就是行为改变，学习人的情感、语言等。另外一个就是获取知识。

对于LLM而言就是输入文本，输出文本

<img src="../assets/9.LLM fine-tuning/image-20240705170414900.png" alt="image-20240705170414900" style="zoom: 50%;" />

### 9.2.3 First time finetuning

1. ldentify task(s) by prompt-engineering a large LLM
2. Find tasks that you see an LLM doing ~OK at
3. Pick one task
4. Get ~1000 inputs and outputs for the task4
5. Better than the ~OK from the LLM
6. Finetune a small LLM on this data